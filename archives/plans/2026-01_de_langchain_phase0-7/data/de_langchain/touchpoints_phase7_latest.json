{
  "root": "D:\\MintBot",
  "patterns": [
    "\\blangchain\\b",
    "\\blangchain[_-]\\w+",
    "\\blanggraph\\b",
    "\\blangsmith\\b"
  ],
  "count": 87,
  "matches": [
    {
      "path": "src/agent/core.py",
      "line": 40,
      "text": "from src.llm_native.langchain_agent import (",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/agent/core.py",
      "line": 53,
      "text": "from src.llm_native.langchain_providers import (",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/agent/core.py",
      "line": 1587,
      "text": "# Phase 0（去 LangChain 计划）：LLM 后端总开关（默认 langchain）",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "src/agent/core.py",
      "line": 1589,
      "text": "getattr(settings.agent, \"llm_backend\", \"langchain\") or \"langchain\"",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "src/agent/core.py",
      "line": 1591,
      "text": "if self._llm_backend not in (\"langchain\", \"native\"):",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "src/agent/mcp_manager.py",
      "line": 23,
      "text": "from src.llm_native.langchain_tools import (",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/agent/tool_selector_middleware.py",
      "line": 29,
      "text": "from src.llm_native.langchain_tool_selector import (",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/agent/tool_selector_middleware.py",
      "line": 302,
      "text": "raise ImportError(\"langchain 未安装，无法通过字符串初始化选择模型\")",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "src/agent/tool_trace_middleware.py",
      "line": 16,
      "text": "from src.llm_native.langchain_agent import AgentMiddleware",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/agent/tool_trace_middleware.py",
      "line": 17,
      "text": "from src.llm_native.langchain_messages import ToolMessage",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/config/settings.py",
      "line": 645,
      "text": "llm_backend: Literal[\"langchain\", \"native\"] = Field(",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "src/config/settings.py",
      "line": 646,
      "text": "default=\"langchain\",",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "src/config/settings.py",
      "line": 647,
      "text": "description=\"LLM 后端实现：langchain（默认）| native（后续 OpenAI-compatible 自研后端）\",",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "src/llm/factory.py",
      "line": 178,
      "text": "from src.llm_native.langchain_providers import get_chat_openai_class",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/llm_native/langchain_agent.py",
      "line": 9,
      "text": "from langchain.agents import create_agent as _create_agent  # type: ignore",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "src/llm_native/langchain_agent.py",
      "line": 27,
      "text": "from langchain.agents.middleware import (  # type: ignore",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "src/llm_native/langchain_backend.py",
      "line": 6,
      "text": "from langchain_core.language_models.chat_models import BaseChatModel",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/llm_native/langchain_backend.py",
      "line": 7,
      "text": "from langchain_core.messages import AIMessage, AIMessageChunk",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/llm_native/langchain_backend.py",
      "line": 11,
      "text": "from .langchain_messages import extract_text, to_langchain_messages",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/llm_native/langchain_messages.py",
      "line": 6,
      "text": "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage, SystemMessage, ToolMessage",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/llm_native/langchain_providers.py",
      "line": 9,
      "text": "from langchain_openai import ChatOpenAI as _ChatOpenAI  # type: ignore",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/llm_native/langchain_providers.py",
      "line": 18,
      "text": "Return `langchain_openai.ChatOpenAI` dynamically.",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/llm_native/langchain_providers.py",
      "line": 20,
      "text": "Note: tests monkeypatch `langchain_openai.ChatOpenAI`, so we must not rely on the",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/llm_native/langchain_providers.py",
      "line": 25,
      "text": "import langchain_openai  # type: ignore",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/llm_native/langchain_providers.py",
      "line": 27,
      "text": "raise ImportError(\"langchain-openai 未安装，无法创建 ChatOpenAI\") from exc",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "src/llm_native/langchain_tools.py",
      "line": 12,
      "text": "from langchain_core.tools import tool as _tool  # type: ignore",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/llm_native/langchain_tools.py",
      "line": 15,
      "text": "from langchain.tools import tool as _tool  # type: ignore",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "src/llm_native/langchain_tools.py",
      "line": 24,
      "text": "from langchain_core.tools import StructuredTool as _LCStructuredTool  # type: ignore",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/llm_native/langchain_tools.py",
      "line": 27,
      "text": "from langchain.tools import StructuredTool as _LCStructuredTool  # type: ignore",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "src/llm_native/langchain_tools.py",
      "line": 39,
      "text": "from langchain_core.tools import BaseTool as _LCBaseTool  # type: ignore",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/llm_native/langchain_tool_selector.py",
      "line": 10,
      "text": "from langchain.agents.middleware.types import (  # type: ignore",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "src/llm_native/langchain_tool_selector.py",
      "line": 27,
      "text": "from langchain.chat_models import init_chat_model as _init_chat_model  # type: ignore",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "src/llm_native/langchain_tool_selector.py",
      "line": 36,
      "text": "from langchain_core.language_models.chat_models import (  # type: ignore",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/llm_native/langchain_tool_selector.py",
      "line": 47,
      "text": "from langchain_core.messages import HumanMessage as _HumanMessage  # type: ignore",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/llm_native/langchain_tool_selector.py",
      "line": 56,
      "text": "from langchain_core.tools import BaseTool as _BaseTool  # type: ignore",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/llm_native/langgraph_types.py",
      "line": 10,
      "text": "from langgraph.prebuilt.tool_node import ToolCallRequest as _ToolCallRequest  # type: ignore",
      "pattern": "\\blanggraph\\b"
    },
    {
      "path": "src/llm_native/langgraph_types.py",
      "line": 11,
      "text": "from langgraph.types import Command as _Command  # type: ignore",
      "pattern": "\\blanggraph\\b"
    },
    {
      "path": "src/multimodal/vision.py",
      "line": 239,
      "text": "from src.llm_native.langchain_messages import to_langchain_messages",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/utils/dependency_checker.py",
      "line": 61,
      "text": "\"langchain\": \"langchain\",",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "src/utils/dependency_checker.py",
      "line": 62,
      "text": "\"langchain_openai\": \"langchain-openai\",",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "src/utils/dependency_checker.py",
      "line": 62,
      "text": "\"langchain_openai\": \"langchain-openai\",",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "src/utils/logger.py",
      "line": 60,
      "text": "\"langchain\",",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "tests/test_llm_factory_base_url_normalization.py",
      "line": 5,
      "text": "import langchain_openai",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "tests/test_llm_factory_base_url_normalization.py",
      "line": 51,
      "text": "monkeypatch.setattr(langchain_openai, \"ChatOpenAI\", DummyChatOpenAI)",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "tests/test_llm_factory_base_url_normalization.py",
      "line": 94,
      "text": "monkeypatch.setattr(langchain_openai, \"ChatOpenAI\", DummyChatOpenAI)",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "tests/test_llm_factory_base_url_normalization.py",
      "line": 137,
      "text": "monkeypatch.setattr(langchain_openai, \"ChatOpenAI\", DummyChatOpenAI)",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "tests/test_llm_native_langchain_backend.py",
      "line": 3,
      "text": "from langchain_core.messages import AIMessage, AIMessageChunk",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "tests/test_llm_native_langchain_backend.py",
      "line": 6,
      "text": "from src.llm_native.langchain_backend import LangChainBackend",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "tests/test_llm_native_langchain_messages.py",
      "line": 3,
      "text": "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage, ToolMessage",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "tests/test_llm_native_langchain_messages.py",
      "line": 5,
      "text": "from src.llm_native.langchain_messages import to_langchain_messages",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "tests/test_stream_extraction.py",
      "line": 5,
      "text": "pytest.importorskip(\"langchain_core\")",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "tests/test_stream_extraction.py",
      "line": 7,
      "text": "from langchain_core.messages import AIMessageChunk, ToolMessage  # noqa: E402",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "tests/test_tool_selector_middleware.py",
      "line": 8,
      "text": "pytest.importorskip(\"langchain\")",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "tests/test_tool_selector_middleware.py",
      "line": 9,
      "text": "pytest.importorskip(\"langchain_core\")",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "tests/test_tool_selector_middleware.py",
      "line": 11,
      "text": "from langchain_core.messages import HumanMessage  # noqa: E402",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "tests/test_tool_trace_middleware.py",
      "line": 3,
      "text": "from langchain_core.messages import ToolMessage",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "tests/test_tool_trace_middleware.py",
      "line": 4,
      "text": "from langchain_core.tools import tool",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "tests/test_tool_trace_middleware.py",
      "line": 5,
      "text": "from langgraph.prebuilt.tool_node import ToolNode",
      "pattern": "\\blanggraph\\b"
    },
    {
      "path": "tests/test_tool_trace_middleware.py",
      "line": 6,
      "text": "from langgraph.runtime import Runtime",
      "pattern": "\\blanggraph\\b"
    },
    {
      "path": "examples/multimodal_complete_demo.py",
      "line": 37,
      "text": "from langchain_openai import ChatOpenAI",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "examples/multimodal_complete_demo.py",
      "line": 58,
      "text": "print(\"⚠️  需要安装依赖 langchain-openai，请先执行: uv sync --locked --no-install-project\")",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "examples/multimodal_complete_demo.py",
      "line": 58,
      "text": "print(\"⚠️  需要安装依赖 langchain-openai，请先执行: uv sync --locked --no-install-project\")",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "examples/multimodal_complete_demo.py",
      "line": 70,
      "text": "from langchain_openai import ChatOpenAI",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "examples/multimodal_complete_demo.py",
      "line": 88,
      "text": "print(\"⚠️  需要安装依赖 langchain-openai，请先执行: uv sync --locked --no-install-project\")",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "scripts/check_install.py",
      "line": 61,
      "text": "(\"langchain\", \"langchain\"),",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "scripts/check_install.py",
      "line": 62,
      "text": "(\"langchain_core\", \"langchain-core\"),",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "scripts/check_install.py",
      "line": 62,
      "text": "(\"langchain_core\", \"langchain-core\"),",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "scripts/check_install.py",
      "line": 63,
      "text": "(\"langchain_community\", \"langchain-community\"),",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "scripts/check_install.py",
      "line": 63,
      "text": "(\"langchain_community\", \"langchain-community\"),",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "scripts/de_langchain_audit_touchpoints.py",
      "line": 5,
      "text": "- 扫描仓库中对 langchain/langgraph/langsmith 的引用位置，输出报告，作为：",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "scripts/de_langchain_audit_touchpoints.py",
      "line": 5,
      "text": "- 扫描仓库中对 langchain/langgraph/langsmith 的引用位置，输出报告，作为：",
      "pattern": "\\blanggraph\\b"
    },
    {
      "path": "scripts/de_langchain_audit_touchpoints.py",
      "line": 5,
      "text": "- 扫描仓库中对 langchain/langgraph/langsmith 的引用位置，输出报告，作为：",
      "pattern": "\\blangsmith\\b"
    },
    {
      "path": "scripts/de_langchain_audit_touchpoints.py",
      "line": 101,
      "text": "description=\"Audit langchain/langgraph/langsmith touchpoints in this repo.\",",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "scripts/de_langchain_audit_touchpoints.py",
      "line": 101,
      "text": "description=\"Audit langchain/langgraph/langsmith touchpoints in this repo.\",",
      "pattern": "\\blanggraph\\b"
    },
    {
      "path": "scripts/de_langchain_capture_golden.py",
      "line": 5,
      "text": "- 录制当前（langchain / native）的流式输出 chunks 与关键性能指标，",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "scripts/de_langchain_capture_golden.py",
      "line": 158,
      "text": "choices=[\"langchain\", \"native\"],",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "scripts/de_langchain_capture_golden.py",
      "line": 159,
      "text": "default=\"langchain\",",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "scripts/de_langchain_capture_golden.py",
      "line": 160,
      "text": "help=\"Backend to capture: langchain (default) or native (OpenAI-compatible).\",",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "scripts/de_langchain_capture_golden.py",
      "line": 168,
      "text": "\"If omitted: langchain->agent, native->backend.\"",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "scripts/de_langchain_compare_golden.py",
      "line": 5,
      "text": "- 对比两份 golden JSON（通常：langchain 后端 vs native 后端）的流式输出结果，",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "scripts/de_langchain_compare_golden.py",
      "line": 18,
      "text": "--baseline data\\\\golden\\\\langchain_backend_stream_golden.json ^",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "scripts/de_langchain_compare_golden.py",
      "line": 123,
      "text": "# Default: Gate#2/#3 langchain vs native.",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "scripts/de_langchain_compare_golden.py",
      "line": 126,
      "text": "Path(\"data/golden/langchain_backend_stream_golden.json\"),",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "scripts/de_langchain_compare_golden.py",
      "line": 127,
      "text": "Path(\"data/golden/langchain_stream_golden.json\"),",
      "pattern": "\\blangchain[_-]\\w+"
    },
    {
      "path": "scripts/quick_start.py",
      "line": 57,
      "text": "import langchain",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "scripts/start.py",
      "line": 132,
      "text": "import langchain  # noqa: F401",
      "pattern": "\\blangchain\\b"
    },
    {
      "path": "scripts/start.py",
      "line": 133,
      "text": "import langchain_core  # noqa: F401",
      "pattern": "\\blangchain[_-]\\w+"
    }
  ]
}