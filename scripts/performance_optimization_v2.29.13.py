#!/usr/bin/env python3
"""
æ€§èƒ½ä¼˜åŒ–è„šæœ¬ v2.29.13
é’ˆå¯¹çƒ­ç‚¹ä»£ç è·¯å¾„è¿›è¡Œæ€§èƒ½ä¼˜åŒ–
"""

import re
from pathlib import Path
from typing import List, Dict, Tuple

PROJECT_ROOT = Path(__file__).parent.parent


class PerformanceOptimizer:
    """æ€§èƒ½ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.optimizations = []
        
    def optimize_string_concatenation(self, file_path: Path) -> int:
        """ä¼˜åŒ–å­—ç¬¦ä¸²æ‹¼æ¥"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            lines = content.split('\n')
        
        optimized = 0
        new_lines = []
        in_loop = False
        loop_indent = 0
        
        for i, line in enumerate(lines):
            stripped = line.strip()
            current_indent = len(line) - len(line.lstrip())
            
            # æ£€æµ‹å¾ªç¯å¼€å§‹
            if re.match(r'^\s*(for|while)\s+', line):
                in_loop = True
                loop_indent = current_indent
            # æ£€æµ‹å¾ªç¯ç»“æŸ
            elif in_loop and current_indent <= loop_indent and stripped:
                in_loop = False
            
            # åœ¨å¾ªç¯ä¸­æ£€æµ‹å­—ç¬¦ä¸²æ‹¼æ¥
            if in_loop and '+=' in line and ('"' in line or "'" in line):
                # æ·»åŠ æ³¨é‡Šæç¤º
                if i > 0 and '# TODO: ä¼˜åŒ–å­—ç¬¦ä¸²æ‹¼æ¥' not in lines[i-1]:
                    new_lines.append(f"{' ' * current_indent}# TODO: ä¼˜åŒ–å­—ç¬¦ä¸²æ‹¼æ¥ï¼Œä½¿ç”¨join()æˆ–åˆ—è¡¨")
                    optimized += 1
            
            new_lines.append(line)
        
        if optimized > 0:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(new_lines))
        
        return optimized
    
    def optimize_regex_compilation(self, file_path: Path) -> int:
        """ä¼˜åŒ–æ­£åˆ™è¡¨è¾¾å¼ç¼–è¯‘"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æŸ¥æ‰¾é‡å¤çš„æ­£åˆ™è¡¨è¾¾å¼
        regex_patterns = re.findall(r're\.(search|match|findall|sub)\(["\'](.+?)["\']\)', content)
        pattern_counts = {}
        for method, pattern in regex_patterns:
            if pattern not in pattern_counts:
                pattern_counts[pattern] = 0
            pattern_counts[pattern] += 1
        
        # æ‰¾å‡ºé‡å¤ä½¿ç”¨çš„æ¨¡å¼
        repeated_patterns = {p: c for p, c in pattern_counts.items() if c > 1}
        
        if repeated_patterns:
            print(f"  å‘ç° {len(repeated_patterns)} ä¸ªé‡å¤çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼")
            for pattern, count in repeated_patterns.items():
                print(f"    - '{pattern[:50]}...' ä½¿ç”¨äº† {count} æ¬¡")
        
        return len(repeated_patterns)
    
    def check_cache_usage(self, file_path: Path) -> Dict[str, int]:
        """æ£€æŸ¥ç¼“å­˜ä½¿ç”¨æƒ…å†µ"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        stats = {
            'cache_get': len(re.findall(r'\.get\(|cache\.get|_cache\[', content)),
            'cache_set': len(re.findall(r'\.set\(|cache\.set|_cache\[.*\]\s*=', content)),
            'cache_check': len(re.findall(r'if.*in.*cache|if.*cache\.get', content)),
        }
        
        return stats
    
    def analyze_hot_paths(self) -> List[Tuple[Path, str]]:
        """åˆ†æçƒ­ç‚¹ä»£ç è·¯å¾„"""
        hot_paths = []
        
        # æ ¸å¿ƒæ¨¡å—
        core_modules = [
            PROJECT_ROOT / "src" / "agent" / "core.py",
            PROJECT_ROOT / "src" / "agent" / "memory.py",
            PROJECT_ROOT / "src" / "utils" / "async_vector_search.py",
            PROJECT_ROOT / "src" / "gui" / "light_chat_window.py",
        ]
        
        for module in core_modules:
            if module.exists():
                hot_paths.append((module, "æ ¸å¿ƒæ¨¡å—"))
        
        return hot_paths
    
    def run_optimization(self):
        """è¿è¡Œä¼˜åŒ–"""
        print("=" * 60)
        print("  æ€§èƒ½ä¼˜åŒ–åˆ†æ v2.29.13")
        print("=" * 60)
        print()
        
        hot_paths = self.analyze_hot_paths()
        
        print(f"ğŸ“Š åˆ†æ {len(hot_paths)} ä¸ªçƒ­ç‚¹æ¨¡å—...\n")
        
        total_string_opts = 0
        total_regex_opts = 0
        
        for file_path, category in hot_paths:
            print(f"ğŸ” {file_path.name} ({category})")
            
            # æ£€æŸ¥å­—ç¬¦ä¸²æ‹¼æ¥
            string_opts = self.optimize_string_concatenation(file_path)
            if string_opts > 0:
                print(f"  âš ï¸  å‘ç° {string_opts} å¤„å­—ç¬¦ä¸²æ‹¼æ¥å¯ä¼˜åŒ–")
                total_string_opts += string_opts
            
            # æ£€æŸ¥æ­£åˆ™è¡¨è¾¾å¼
            regex_opts = self.optimize_regex_compilation(file_path)
            total_regex_opts += regex_opts
            
            # æ£€æŸ¥ç¼“å­˜ä½¿ç”¨
            cache_stats = self.check_cache_usage(file_path)
            if cache_stats['cache_get'] > 0:
                print(f"  âœ… ç¼“å­˜ä½¿ç”¨: get={cache_stats['cache_get']}, "
                      f"set={cache_stats['cache_set']}, check={cache_stats['cache_check']}")
            
            print()
        
        print("=" * 60)
        print("  ä¼˜åŒ–å»ºè®®æ€»ç»“")
        print("=" * 60)
        print(f"  å­—ç¬¦ä¸²æ‹¼æ¥ä¼˜åŒ–: {total_string_opts} å¤„")
        print(f"  æ­£åˆ™è¡¨è¾¾å¼ä¼˜åŒ–: {total_regex_opts} å¤„")
        print()
        
        if total_string_opts > 0:
            print("ğŸ’¡ å»ºè®®:")
            print("  - å¾ªç¯ä¸­çš„å­—ç¬¦ä¸²æ‹¼æ¥æ”¹ç”¨ join() æˆ–åˆ—è¡¨ç´¯ç§¯")
            print("  - ä½¿ç”¨ f-string æ›¿ä»£ + æ‹¼æ¥")
            print()
        
        if total_regex_opts > 0:
            print("ğŸ’¡ å»ºè®®:")
            print("  - å°†é‡å¤ä½¿ç”¨çš„æ­£åˆ™è¡¨è¾¾å¼é¢„ç¼–è¯‘ä¸ºæ¨¡å—çº§å¸¸é‡")
            print("  - ç¤ºä¾‹: PATTERN = re.compile(r'...')")
            print()


def main():
    optimizer = PerformanceOptimizer()
    optimizer.run_optimization()


if __name__ == "__main__":
    main()

