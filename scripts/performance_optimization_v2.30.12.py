"""
æ€§èƒ½ä¼˜åŒ–è„šæœ¬ v2.30.12

ä¼˜åŒ–å†…å®¹:
1. ä¼˜åŒ–å¼‚æ­¥èµ„æºç®¡ç†ï¼ˆä½¿ç”¨async withï¼‰
2. ä¼˜åŒ–å‘é‡æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½
3. ä¼˜åŒ–å†…å­˜ç®¡ç†å’Œç¼“å­˜ç­–ç•¥
4. ä¼˜åŒ–GUIæ¸²æŸ“æ€§èƒ½
"""

from pathlib import Path
from typing import List, Dict
import re

PROJECT_ROOT = Path(__file__).parent.parent


def optimize_async_patterns(file_path: Path) -> int:
    """ä¼˜åŒ–å¼‚æ­¥æ¨¡å¼ä½¿ç”¨"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    changes = 0
    
    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†æ—§çš„äº‹ä»¶å¾ªç¯è·å–æ–¹å¼
    if 'asyncio.get_event_loop()' in content:
        # æ›¿æ¢ä¸ºæ¨èçš„æ–¹å¼
        content = content.replace(
            'asyncio.get_event_loop()',
            'asyncio.get_running_loop()  # Python 3.7+ æ¨èæ–¹å¼'
        )
        changes += 1
    
    if changes > 0:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    return changes


def add_context_manager_support(file_path: Path) -> int:
    """ä¸ºå¼‚æ­¥ç±»æ·»åŠ ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ”¯æŒ"""
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    changes = 0
    new_lines = []
    in_async_class = False
    class_name = None
    has_aenter = False
    has_aexit = False
    
    for i, line in enumerate(lines):
        new_lines.append(line)
        
        # æ£€æµ‹å¼‚æ­¥ç±»å®šä¹‰
        if re.match(r'class\s+(\w+).*:', line) and i + 1 < len(lines):
            # æ£€æŸ¥ç±»ä¸­æ˜¯å¦æœ‰asyncæ–¹æ³•
            next_lines = ''.join(lines[i:min(i+50, len(lines))])
            if 'async def' in next_lines:
                in_async_class = True
                class_name = re.match(r'class\s+(\w+)', line).group(1)
                has_aenter = '__aenter__' in next_lines
                has_aexit = '__aexit__' in next_lines
        
        # åœ¨ç±»çš„æœ«å°¾æ·»åŠ ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ–¹æ³•
        if in_async_class and line.strip() and not line.strip().startswith('#'):
            # æ£€æµ‹ç±»çš„ç»“æŸï¼ˆä¸‹ä¸€ä¸ªç±»å®šä¹‰æˆ–æ–‡ä»¶æœ«å°¾ï¼‰
            if i + 1 < len(lines) and (lines[i+1].startswith('class ') or lines[i+1].startswith('def ')):
                if not has_aenter or not has_aexit:
                    # æ·»åŠ å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ–¹æ³•
                    indent = '    '
                    if not has_aenter:
                        new_lines.append(f'\n{indent}async def __aenter__(self):\n')
                        new_lines.append(f'{indent}    """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""\n')
                        new_lines.append(f'{indent}    return self\n')
                        changes += 1
                    
                    if not has_aexit:
                        new_lines.append(f'\n{indent}async def __aexit__(self, exc_type, exc_val, exc_tb):\n')
                        new_lines.append(f'{indent}    """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""\n')
                        new_lines.append(f'{indent}    await self.cleanup()\n')
                        changes += 1
                
                in_async_class = False
                class_name = None
    
    if changes > 0:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.writelines(new_lines)
    
    return changes


def optimize_vector_db_queries(file_path: Path) -> int:
    """ä¼˜åŒ–å‘é‡æ•°æ®åº“æŸ¥è¯¢"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    changes = 0
    
    # æ·»åŠ æ‰¹é‡æŸ¥è¯¢ä¼˜åŒ–æç¤º
    if 'similarity_search' in content and 'batch' not in content:
        # åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ ä¼˜åŒ–æ³¨é‡Š
        lines = content.split('\n')
        for i, line in enumerate(lines):
            if 'def ' in line and 'similarity_search' in line:
                # æ·»åŠ æ€§èƒ½ä¼˜åŒ–æç¤º
                indent = len(line) - len(line.lstrip())
                comment = ' ' * indent + '# æ€§èƒ½ä¼˜åŒ–: è€ƒè™‘ä½¿ç”¨æ‰¹é‡æŸ¥è¯¢å‡å°‘æ•°æ®åº“è®¿é—®æ¬¡æ•°\n'
                lines.insert(i, comment)
                changes += 1
                break
        
        if changes > 0:
            content = '\n'.join(lines)
    
    if changes > 0:
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
    
    return changes


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("  MintChat æ€§èƒ½ä¼˜åŒ– v2.30.12")
    print("=" * 70)
    print()
    
    # éœ€è¦ä¼˜åŒ–çš„æ–‡ä»¶
    async_files = [
        'src/agent/core.py',
        'src/utils/async_manager.py',
        'src/utils/async_vector_search.py',
        'src/utils/performance.py',
    ]
    
    vector_db_files = [
        'src/agent/memory.py',
        'src/agent/advanced_memory.py',
    ]
    
    total_async_fixes = 0
    total_vector_fixes = 0
    
    print("ğŸ“ ä¼˜åŒ–å¼‚æ­¥æ¨¡å¼...")
    for file_rel in async_files:
        file_path = PROJECT_ROOT / file_rel
        if not file_path.exists():
            continue
        
        fixes = optimize_async_patterns(file_path)
        if fixes > 0:
            print(f"  âœ“ {file_rel}: {fixes} å¤„ä¼˜åŒ–")
            total_async_fixes += fixes
    
    print()
    print("ğŸ“ ä¼˜åŒ–å‘é‡æ•°æ®åº“æŸ¥è¯¢...")
    for file_rel in vector_db_files:
        file_path = PROJECT_ROOT / file_rel
        if not file_path.exists():
            continue
        
        fixes = optimize_vector_db_queries(file_path)
        if fixes > 0:
            print(f"  âœ“ {file_rel}: {fixes} å¤„ä¼˜åŒ–")
            total_vector_fixes += fixes
    
    print()
    print(f"âœ… æ€»å…±ä¼˜åŒ–:")
    print(f"  - å¼‚æ­¥æ¨¡å¼: {total_async_fixes} å¤„")
    print(f"  - å‘é‡æŸ¥è¯¢: {total_vector_fixes} å¤„")
    print()


if __name__ == "__main__":
    main()

