"""
æµ‹è¯•æ€§èƒ½ä¼˜åŒ– v2.30.44

æµ‹è¯•å†…å®¹ï¼š
1. å¤šçº§ç¼“å­˜æ€§èƒ½
2. å¼‚æ­¥å¤„ç†æ€§èƒ½
3. ChromaDB å‚æ•°ä¼˜åŒ–
4. æ•´ä½“æ€§èƒ½å¯¹æ¯”
"""

import sys
import os
import time
from pathlib import Path

# è®¾ç½®ç¼–ç 
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.agent.advanced_memory import LoreBook
from src.config.settings import settings


def test_cache_performance():
    """æµ‹è¯•ç¼“å­˜æ€§èƒ½"""
    print("\n" + "="*60)
    print("æµ‹è¯• 1: å¤šçº§ç¼“å­˜æ€§èƒ½")
    print("="*60)
    
    lore_book = LoreBook()
    
    # æ·»åŠ æµ‹è¯•çŸ¥è¯†
    print("\næ·»åŠ æµ‹è¯•çŸ¥è¯†...")
    test_lores = []
    for i in range(20):
        lore_id = lore_book.add_lore(
            title=f"æµ‹è¯•çŸ¥è¯† {i+1}",
            content=f"è¿™æ˜¯ç¬¬ {i+1} æ¡æµ‹è¯•çŸ¥è¯†ï¼Œç”¨äºæµ‹è¯•ç¼“å­˜æ€§èƒ½ã€‚",
            category="test",
            keywords=[f"æµ‹è¯•{i+1}", "ç¼“å­˜", "æ€§èƒ½"],
            source="test",
            skip_quality_check=True,
        )
        if lore_id:
            test_lores.append(lore_id)
    
    print(f"âœ… æ·»åŠ æˆåŠŸ: {len(test_lores)} æ¡")
    
    # æµ‹è¯•æœç´¢æ€§èƒ½ï¼ˆæ— ç¼“å­˜ï¼‰
    print("\næµ‹è¯•æœç´¢æ€§èƒ½ï¼ˆæ— ç¼“å­˜ï¼‰...")
    query = "æµ‹è¯•çŸ¥è¯†"
    
    times_no_cache = []
    for i in range(5):
        start = time.time()
        results = lore_book.search_lore(query, k=5, use_cache=False)
        elapsed = (time.time() - start) * 1000
        times_no_cache.append(elapsed)
        print(f"  ç¬¬ {i+1} æ¬¡: {elapsed:.2f}msï¼Œæ‰¾åˆ° {len(results)} æ¡")
    
    avg_no_cache = sum(times_no_cache) / len(times_no_cache)
    print(f"  å¹³å‡æ—¶é—´: {avg_no_cache:.2f}ms")
    
    # æµ‹è¯•æœç´¢æ€§èƒ½ï¼ˆæœ‰ç¼“å­˜ï¼‰
    print("\næµ‹è¯•æœç´¢æ€§èƒ½ï¼ˆæœ‰ç¼“å­˜ï¼‰...")
    
    times_with_cache = []
    for i in range(5):
        start = time.time()
        results = lore_book.search_lore(query, k=5, use_cache=True)
        elapsed = (time.time() - start) * 1000
        times_with_cache.append(elapsed)
        print(f"  ç¬¬ {i+1} æ¬¡: {elapsed:.2f}msï¼Œæ‰¾åˆ° {len(results)} æ¡")
    
    avg_with_cache = sum(times_with_cache) / len(times_with_cache)
    print(f"  å¹³å‡æ—¶é—´: {avg_with_cache:.2f}ms")
    
    # è®¡ç®—æå‡
    speedup = avg_no_cache / avg_with_cache if avg_with_cache > 0 else 0
    print(f"\nğŸš€ ç¼“å­˜æå‡: {speedup:.1f}x")
    
    # è·å–ç¼“å­˜ç»Ÿè®¡
    if lore_book.multi_cache:
        stats = lore_book.multi_cache.get_stats()
        print(f"\nç¼“å­˜ç»Ÿè®¡:")
        print(f"  L1 å‘½ä¸­: {stats['l1_hits']}")
        print(f"  L2 å‘½ä¸­: {stats['l2_hits']}")
        print(f"  æœªå‘½ä¸­: {stats['misses']}")
        print(f"  å‘½ä¸­ç‡: {stats['hit_rate']:.1%}")
        print(f"  L1 å¤§å°: {stats['l1_size']}")
        print(f"  Redis è¿æ¥: {'æ˜¯' if stats['redis_connected'] else 'å¦'}")
    
    print("\nâœ… ç¼“å­˜æ€§èƒ½æµ‹è¯•å®Œæˆ")


def test_batch_performance():
    """æµ‹è¯•æ‰¹é‡æ“ä½œæ€§èƒ½"""
    print("\n" + "="*60)
    print("æµ‹è¯• 2: æ‰¹é‡æ“ä½œæ€§èƒ½")
    print("="*60)
    
    lore_book = LoreBook()
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    test_lores = []
    for i in range(50):
        test_lores.append({
            "title": f"æ‰¹é‡æµ‹è¯•çŸ¥è¯† {i+1}",
            "content": f"è¿™æ˜¯ç¬¬ {i+1} æ¡æ‰¹é‡æµ‹è¯•çŸ¥è¯†ã€‚",
            "category": "batch_test",
            "keywords": [f"æ‰¹é‡{i+1}", "æµ‹è¯•"],
            "source": "batch_test",
        })
    
    # æµ‹è¯•æ‰¹é‡æ·»åŠ 
    print(f"\næ‰¹é‡æ·»åŠ  {len(test_lores)} æ¡çŸ¥è¯†...")
    start = time.time()
    added_ids = lore_book.batch_add_lores(test_lores)
    time_batch = (time.time() - start) * 1000
    print(f"âœ… æ‰¹é‡æ·»åŠ æˆåŠŸ: {len(added_ids)} æ¡")
    print(f"â±ï¸ æ‰¹é‡æ·»åŠ æ—¶é—´: {time_batch:.2f}ms")
    print(f"â±ï¸ å¹³å‡æ¯æ¡: {time_batch / len(added_ids):.2f}ms")
    
    print("\nâœ… æ‰¹é‡æ“ä½œæ€§èƒ½æµ‹è¯•å®Œæˆ")


def test_overall_performance():
    """æµ‹è¯•æ•´ä½“æ€§èƒ½"""
    print("\n" + "="*60)
    print("æµ‹è¯• 3: æ•´ä½“æ€§èƒ½å¯¹æ¯”")
    print("="*60)
    
    lore_book = LoreBook()
    
    # è·å–æ‰€æœ‰çŸ¥è¯†
    print("\nè·å–æ‰€æœ‰çŸ¥è¯†...")
    start = time.time()
    all_lores = lore_book.get_all_lores(use_cache=True)
    time_get_all = (time.time() - start) * 1000
    print(f"âœ… è·å–æˆåŠŸ: {len(all_lores)} æ¡")
    print(f"â±ï¸ è·å–æ—¶é—´: {time_get_all:.2f}ms")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    print("\nè·å–ç»Ÿè®¡ä¿¡æ¯...")
    start = time.time()
    stats = lore_book.get_statistics()
    time_stats = (time.time() - start) * 1000
    print(f"âœ… ç»Ÿè®¡ä¿¡æ¯:")
    print(f"  æ€»æ•°: {stats['total']}")
    print(f"  ç±»åˆ«: {stats['by_category']}")
    print(f"â±ï¸ ç»Ÿè®¡æ—¶é—´: {time_stats:.2f}ms")
    
    # æœç´¢æ€§èƒ½
    print("\næœç´¢æ€§èƒ½...")
    queries = ["æµ‹è¯•", "çŸ¥è¯†", "æ‰¹é‡", "æ€§èƒ½", "ç¼“å­˜"]
    total_time = 0
    total_results = 0
    
    for query in queries:
        start = time.time()
        results = lore_book.search_lore(query, k=5, use_cache=True)
        elapsed = (time.time() - start) * 1000
        total_time += elapsed
        total_results += len(results)
        print(f"  æŸ¥è¯¢ '{query}': {elapsed:.2f}msï¼Œæ‰¾åˆ° {len(results)} æ¡")
    
    avg_search_time = total_time / len(queries)
    print(f"  å¹³å‡æœç´¢æ—¶é—´: {avg_search_time:.2f}ms")
    
    print("\nâœ… æ•´ä½“æ€§èƒ½æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    print("="*60)
    print("æ€§èƒ½ä¼˜åŒ–æµ‹è¯• v2.30.44")
    print("="*60)
    
    try:
        test_cache_performance()
        test_batch_performance()
        test_overall_performance()
        
        print("\n" + "="*60)
        print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        print("="*60)
    
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

